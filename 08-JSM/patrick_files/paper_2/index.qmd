---
format: 
  revealjs:
    transition-speed: fast
    slide-number: c/t
    css: custom.css
    transition: fade
    incremental: true 
    theme: default
    footer: "Slides URL: <https://autovi.netlify.app>"
    logo: figures/monash-stacked-blue-rgb.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  cache = FALSE,
  echo = FALSE,
  message = FALSE, 
  warning = FALSE
)

library(tidyverse)
library(glue)
```

## autovi: Automated Assessment of Residual Plots Using Computer Vision {.center style="text-align: right;"}

::: {style="color: #5A5A5A"}

useR! 2024

:::


#### Weihao (Patrick) Li {style="margin-top: 40px; font-size: 0.9em"}

::: {style="font-size: 0.9em"}

Monash University

:::

---

## ‚úçÔ∏èCo-authors {visibility="hidden"}

::: {.columns style="font-size:50%"}

::: {.column width="25%"}

![](figures/dicook.jpg){style="object-fit: cover; width: 100%; aspect-ratio: 1 / 1;"}

Professor Dianne Cook, Department of Econometrics and Business Statistics, Melbourne, Monash University, Australia

:::

::: {.column width="25%"}

![](figures/emitanaka.jpg){style="object-fit: cover; width: 100%; aspect-ratio: 1 / 1;"}

Dr. Emi Tanaka, Biological Data Science Institute, Australian National University, Canberra, Australia

:::


::: {.column width="25%"}

![](figures/susan.jpg){style="object-fit: cover; width: 100%; aspect-ratio: 1 / 1;"}

Assistant Professor Susan VanderPlas, Statistics Department, University of Nebraska, Lincoln, USA

:::

::: {.column width="25%"}

![](figures/klaus.jpeg){style="object-fit: cover; width: 100%; aspect-ratio: 1 / 1;"}

Senior Lecturer Klaus Ackermann, Department of Econometrics and Business Statistics, Melbourne, Monash University, Australia

:::

:::

---

## üìùOverview

1. Brief introduction to lineup
2. Outline of the computer vision model
3. `autovi` Package
4. Shiny app demo

---

## üîçRegression Diagnostics

Diagnostics are the key to determining whether there is anything **importantly wrong** with a regression model. 

<br>

$$\underbrace{\boldsymbol{e}}_\textrm{Residuals} = \underbrace{\boldsymbol{y}}_\textrm{Observations} - \underbrace{f(\boldsymbol{x})}_\textrm{Fitted values}$$

**Graphical approaches (plots)** are the recommended methods for diagnosing residuals.


---

## ü§îChallenges

:::: {.columns}

::: {.column width="40%"}

```{r fig.width=5, fig.height=5, fig.retina=3, warning=FALSE, message=FALSE}
library(tidyverse)
library(visage)
set.seed(452)
ori_x <- rand_lognormal()
mod <- heter_model(b = 0, x = closed_form(~-ori_x))
ori_dat <- mod$gen(300)

ori_dat %>%
  VI_MODEL$plot(theme = theme_light(base_size = 18), size = 1, remove_grid_line = TRUE, ) +
  # geom_line(aes(x = .fitted, y = (3.5 + 0.3 * .fitted)), col = "red") +
  # geom_line(aes(x = .fitted, y = -(3.5 + 0.3 * .fitted)), col = "red") +
  xlab("Fitted values") +
  ylab("Residuals")
```

:::


::: {.column width="60%"}

- Vertical spread of the points varies with the fitted values indicates **the existence of heteroskedasticity**.

- However, this is an **over-interpretation**.

- The visual pattern is caused by a **skewed distribution of the predictor**.



:::

::::


---

## üî¨Visual Inference

::: {style="font-size:70%"}

The reading of residual plots can be **calibrated** by an **inferential framework** called **visual inference** (Buja, et al. 2009).

:::: {.columns}

::: {.column width="50%"}


```{r fig.width=5, fig.height=5, fig.retina=3}
set.seed(452)
mod$gen_lineup(300, k = 20, pos = 11) %>%
  filter(null != FALSE) %>%
  bind_rows(ori_dat %>% mutate(k = 11, null = FALSE)) %>%
  VI_MODEL$plot_lineup(theme = theme_light(base_size = 12),
                       remove_grid_line = TRUE,
                       remove_axis = TRUE)
```

:::

::: {.column width="50%"}

::: {.fragment}

Typically, a **lineup** of residual plots consists of 

<!-- - $m$ randomly placed plots -->
- one **actual residual plot**
- $19$ **null plots** containing residuals **simulated from the fitted model**.

:::

::: {.fragment}

To perform a visual test

- Observer(s) will be asked to select the **most different plot(s)**.
- The p-value can be calculated using the **beta-binomial model** (VanderPlas et al., 2021).

:::

:::


::::

:::


---

## üö´Limitations of Lineup Protocol

::: {.fragment}
1. Human can not 

- evaluate lineup consisted of a **large number of plots**.
- evaluate a **large number of lineups**.
:::

::: {.fragment}
2. Evaluation of lineup is **high in labour cost** and **time consuming**.
:::

---

## ü§ñComputer Vision Model

Modern **computer vision models** are well-suited for addressing this challenge. 

![Source: https://en.wikipedia.org/wiki/Convolutional_neural_network](figures/Typical_cnn.png)

---

## üìèMeasure the Difference

To develop computer vision models assessing lineups of residual plots, we need to define a **numerical measure** of **"difference"** or **"distance"** between plots.

- pixel-wise sum of square differences
- Structural Similarity Index Measure (SSIM)
- scagnostics
- ...

---

## üé≤Residual Distribution {visibility="hidden"}

Consider the **classical normal linear regression model**

$$\boldsymbol{y} = \boldsymbol{X}\boldsymbol{\beta} + \boldsymbol{\varepsilon}, \quad \boldsymbol{\varepsilon} \sim N(\boldsymbol{0}_n, \sigma^2\boldsymbol{I}_n).$$

By the **Frisch-Waugh-Lowell theorem**,

$$\boldsymbol{e} = \boldsymbol{R}\boldsymbol{\varepsilon},$$
where $\boldsymbol{R}=\boldsymbol{I}_n -\boldsymbol{X}(\boldsymbol{X}'\boldsymbol{X})^{-1}\boldsymbol{X}'$.

We treat $\boldsymbol{e}$ as **a vector of random variables** here.

---


## üé≤Residual Distribution {visibility="hidden"}

For a **correctly specified model**, $$\boldsymbol{e} \sim N(\boldsymbol{0}_n, \text{diag}(\boldsymbol{R}\sigma^2)).$$ 

For simplicity, we will replace $\text{cov}(\boldsymbol{e}, \boldsymbol{e}) = \boldsymbol{R}\boldsymbol{R}'\sigma^2 = \boldsymbol{R}\sigma^2$ with a **full-rank diagonal matrix** $\text{diag}(\boldsymbol{R}\sigma^2)$.

Symbol $Q$ will be used to represent this **reference residual distribution**. 



---

## üé≤Residual Distribution {visibility="hidden"}

::: {style="font-size:80%"}

However, if the model is **misspecified**, then the **actual residual distribution** denoted as $P$, will be **different** from $Q$.

- If $\boldsymbol{\varepsilon} \sim N(\boldsymbol{0}_n,\boldsymbol{V})$, where $\boldsymbol{V} \neq \sigma^2\boldsymbol{I}_n$,  $$\boldsymbol{e} \sim N(\boldsymbol{0}_n, \text{diag}(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R})) \implies \text{Heteroskedasticity}.$$

- And if some necessary higher-order predictors $\boldsymbol{Z}$ are also omitted, $$\boldsymbol{e} \sim N(\boldsymbol{R}\boldsymbol{Z}\boldsymbol{\beta}_z, \text{diag}(\boldsymbol{R}\boldsymbol{V}\boldsymbol{R})) \implies \text{Non-linearity}~ \& ~\text{Heteroskedasticity}.$$

:::

---

## üìèKL Divergence of $P$ from $Q$

::: {style="font-size:80%"}

We defined a **distance measure** based on **Kullback-Leibler divergence** to quantify the **extent of model violations**

\begin{align}
\label{eq:kl-0}
D &= \log\left(1 + \int_{\mathbb{R}^{n}}\log\frac{p(\boldsymbol{e})}{q(\boldsymbol{e})}p(\boldsymbol{e})d\boldsymbol{e}\right), \\
\end{align}

- $P$: **reference residual distribution** assumed under correct model specification.
- $Q$: **actual residual distribution**.

- $D = 0$ if and only if $P \equiv Q$.
- However, $Q$ is typically unknown $\Rightarrow$ $D$ can not be computed.

:::


---

## üéØEstimation of the Distance

::: {.fragment}

We can train a **computer vision model** to estimate $D$ with **a residual plot**

\begin{equation}
\label{eq:d-approx}
\widehat{D} = f_{CV}(V_{h \times w}(\boldsymbol{e}, \boldsymbol{\hat{y}})),
\end{equation}

where $V_{h \times w}(.)$ is a **plotting function** that saves a residual plot as an image with $h \times w$ pixels, and  $f_{CV}(.)$ is a **computer vision model** which predicts distance in $[0, +\infty)$.

:::

---

## üî¨Statistical Testing

The **null distribution** can be estimated by predicting $\widehat{D}$ for **a large number of null plots**. 

- The **critical value** can be estimated by the **sample quantile** (e.g. $Q_{null}(0.95)$) of the null distribution.

- The **$p$-value** is the proportion of null plots having estimated distance **greater than or equal to** the observed one.



---

## üí°Non-linearity {visibility="hidden"}


:::: {.columns}

::: {.column width="70%"}

```{r fig.width=10, fig.height=4}
set.seed(10086)

# Data for shape 1
dat_shape_1 <- phn_model(j = 2, include_x2 = FALSE, sigma = 0.05)$gen(500) %>%
  mutate(j = 2)

# Generate data for shape 2, 3 and 4. Reuse x and e.
map_df(3:11, function(j) {
  phn_model(j = j, include_x2 = FALSE, sigma = 0.05)$
    gen(500, computed = select(dat_shape_1, x1, e)) %>%
  mutate(j = j)
}) %>%
  
# Combined with data for shape 1
bind_rows(dat_shape_1) %>%
  mutate(j = factor(j)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~j, scales = "free", labeller = label_parsed, ncol = 5)
```

:::

:::


:::: {.columns}

::: {.column width="70%"}

```{r fig.width=8, fig.height=2}
set.seed(10086)

# Data for shape 1
dat_shape_1 <- phn_model(j = 2, include_x2 = FALSE, sigma = 0.05)$gen(500) %>%
  mutate(e_sigma = 0.2)

# Generate data for shape 2, 3 and 4. Reuse x and e.
map_df(c(0.4, 0.8, 1.6, 3.2), function(e_sigma) {
  phn_model(j = 2, include_x2 = FALSE, sigma = e_sigma)$
    gen(500, computed = select(dat_shape_1, x1, e) %>% mutate(e = e/0.2*e_sigma)) %>%
  mutate(e_sigma = e_sigma)
}) %>%
  
# Combined with data for shape 1
bind_rows(dat_shape_1) %>%
  mutate(e_sigma = factor(e_sigma)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~e_sigma, scales = "free", labeller = label_parsed, ncol = 5)
```

:::

:::

---


## üí°Heteroskedasticity {visibility="hidden"}



:::: {.columns}

::: {.column width="70%"}

```{r fig.width=10, fig.height=4}
set.seed(10085)

# Generate data for a = -1
dat_a_n1 <- phn_model(include_z = FALSE,
                      include_x2 = FALSE,
                      a = -1,
                      b = 100)$gen(500) %>%
  mutate(a = -1)

# Generate data for other a
map(c(-0.75, -0.5, -0.25, 0, 0.25, 0.5, 0.75, 1), function(a) {
  phn_model(include_z = FALSE,
            include_x2 = FALSE,
            a = a,
            b = 100)$gen(500) %>%
  mutate(a = a)
}) %>%
  
  # Combined with data for a = -1
  bind_rows(dat_a_n1) %>%
  mutate(a = factor(a)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~a, scales = "free", ncol = 5) +
  xlab("Fitted values") +
  ylab("Residuals")
```

:::

:::


:::: {.columns}

::: {.column width="70%"}

```{r fig.width=8, fig.height=2}
set.seed(10085)

# Generate data for a = -1
dat_a_n1 <- phn_model(include_z = FALSE,
                      include_x2 = FALSE,
                      a = -1,
                      b = 6)$gen(500) %>%
  mutate(b = 6)

# Generate data for other a
map(c(3, 1.5, 1, 0.5), function(b) {
  phn_model(include_z = FALSE,
            include_x2 = FALSE,
            a = -1,
            b = b)$gen(500) %>%
  mutate(b = b)
}) %>%
  
  # Combined with data for a = -1
  bind_rows(dat_a_n1) %>%
  mutate(b = factor(b)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~b, scales = "free", ncol = 5) +
  xlab("Fitted values") +
  ylab("Residuals")
```

:::

:::

---

## üí°Non-normality {visibility="hidden"}



:::: {.columns}

::: {.column width="30%"}


**Distribution of $\varepsilon$**

:::

::: {.column width="70%"}

```{r fig.width=8, fig.height=6}
set.seed(10086)

# Data for shape 1
dat_shape_1 <- phn_model(include_z = FALSE, include_x2 = FALSE, e = rand_uniform(-1.4, 1.4))$gen(500) %>%
  mutate(e_dist = "uniform")

dat_shape_2 <- phn_model(include_z = FALSE, include_x2 = FALSE, sigma = 0.8)$gen(500) %>%
  mutate(e_dist = "normal")

dat_shape_3 <- phn_model(include_z = FALSE, include_x2 = FALSE, e = rand_lognormal(sigma = 0.6))$gen(500) %>%
  mutate(e_dist = "lognormal")

dat_shape_4 <- phn_model(include_z = FALSE, include_x2 = FALSE, e = rand_uniform_d(-1.4, 1.4, even = TRUE))$gen(500) %>%
  mutate(e_dist = "discrete")

# Generate data for shape 2, 3 and 4. Reuse x and e.
bind_rows(dat_shape_1, dat_shape_2, dat_shape_3, dat_shape_4) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~e_dist, scales = "free", labeller = label_parsed, ncol = 2)
```

:::

:::


---


## üí°Training: Various Model Violations

::: {.columns}

::: {.column width="30%"}

**Non-linearity + Heteroskedasticity**

:::

::: {.column width="70%"}


```{r fig.width=10, fig.height=4}
set.seed(10086)

# Data for shape 1
dat_shape_1 <- phn_model(j = 2, a = -1, b = 100, include_x2 = FALSE, sigma = 0.05)$gen(500) %>%
  mutate(j = 2)

# Generate data for shape 2, 3 and 4. Reuse x and e.
map_df(3:11, function(j) {
  phn_model(j = j, a = -1, b = 100, include_x2 = FALSE, sigma = 0.05)$
    gen(500, computed = select(dat_shape_1, x1, e)) %>%
  mutate(j = j)
}) %>%
  
  # Combined with data for shape 1
  bind_rows(dat_shape_1) %>%
  mutate(j = factor(j)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~j, scales = "free", labeller = label_parsed, ncol = 5)
```

:::

:::


::: {.columns}

::: {.column width="30%"}

**Non-normality + Heteroskedasticity**

:::

::: {.column width="70%"}


```{r fig.width=8, fig.height=2}
set.seed(10085)

# Data for shape 1
dat_shape_1 <- phn_model(a = -1, b = 100, include_z = FALSE, include_x2 = FALSE, e = rand_uniform(-1.4, 1.4))$gen(500) %>%
  mutate(e_dist = "uniform")

dat_shape_2 <- phn_model(a = -1, b = 100, include_z = FALSE, include_x2 = FALSE, sigma = 0.8)$gen(500) %>%
  mutate(e_dist = "normal")

dat_shape_3 <- phn_model(a = -1, b = 100, include_z = FALSE, include_x2 = FALSE, e = rand_lognormal(sigma = 0.6))$gen(500) %>%
  mutate(e_dist = "lognormal")

dat_shape_4 <- phn_model(a = -1, b = 100, include_z = FALSE, include_x2 = FALSE, e = rand_uniform_d(-1.4, 1.4, even = TRUE))$gen(500) %>%
  mutate(e_dist = "discrete")

# Generate data for shape 2, 3 and 4. Reuse x and e.
bind_rows(dat_shape_1, dat_shape_2, dat_shape_3, dat_shape_4) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~e_dist, scales = "free", labeller = label_parsed, ncol = 4)
```

:::

:::

---

## üí°Training: Predictor Distribution


::: {.columns}

::: {.column width="30%"}

**Distribution of predictor**

:::

::: {.column width="70%"}


```{r fig.width=8, fig.height=6}
set.seed(10086)

stand_dist <- function(x) (x - min(x))/max(x - min(x)) * 2 - 1

# Data for uniform distribution
dat_dist_1 <- poly_model(shape = 1, 
                      x = {
                        raw_x <- rand_uniform(-1, 1);
                        closed_form(~stand_dist(raw_x))
                        }, 
                      sigma = 0.5)$gen(300) %>%
  mutate(x_dist = "uniform")

# Generate data for other distributions
dat_dist_2 <- poly_model(shape = 1,
                         x = {
                           raw_x <- rand_normal(sigma = 0.3); 
                           closed_form(~stand_dist(raw_x))
                           }, 
                         sigma = 0.5)$
  gen(300, computed = select(dat_dist_1, e)) %>%
  mutate(x_dist = "normal")

dat_dist_3 <- poly_model(shape = 1,
                         x = {
                           raw_x <- rand_lognormal(sigma = 0.6); 
                           closed_form(~stand_dist(raw_x/3 - 1))
                           }, 
                         sigma = 0.5)$
  gen(300, computed = select(dat_dist_1, e)) %>%
  mutate(x_dist = "lognormal")

dat_dist_4 <- poly_model(shape = 1,
                         x = {
                           raw_x <- rand_uniform_d(k = 5, even = TRUE); 
                           closed_form(~stand_dist(raw_x))
                           }, 
                         sigma = 0.5)$
  gen(300, computed = select(dat_dist_1, e)) %>%
  mutate(x_dist = "discrete")

# Generate and plot data for discrete uniform distribution
bind_rows(dat_dist_1, dat_dist_2, dat_dist_3, dat_dist_4) %>%
  mutate(x_dist = factor(x_dist, 
                         levels = c("discrete", 
                                    "lognormal", 
                                    "normal", 
                                    "uniform"))) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  xlab("Fitted values") +
  ylab("Residuals") +
  facet_wrap(~x_dist, ncol = 2, scales = "free")
```

:::

:::

---

## üí°Second Predictor {visibility="hidden"}




::: {.columns}

::: {.column width="30%"}

**Non-linearity + Second predictor**

:::

::: {.column width="70%"}


```{r fig.width=10, fig.height=4}
set.seed(10086)

# Data for shape 1
dat_shape_1 <- phn_model(j = 2, include_x2 = TRUE, sigma = 0.05)$gen(500) %>%
  mutate(j = 2)

# Generate data for shape 2, 3 and 4. Reuse x and e.
map_df(3:11, function(j) {
  phn_model(j = j, include_x2 = TRUE, sigma = 0.05)$
    gen(500, computed = select(dat_shape_1, x1, e)) %>%
  mutate(j = j)
}) %>%
  
  # Combined with data for shape 1
  bind_rows(dat_shape_1) %>%
  mutate(j = factor(j)) %>%
  VI_MODEL$plot(remove_axis = TRUE, remove_grid_line = TRUE, theme = theme_light(base_size = 15)) +
  facet_wrap(~j, scales = "free", labeller = label_parsed, ncol = 5)
```

:::

:::

---

## üèõÔ∏èModel Architecture

The architecture of the computer vision model is adapted from **VGG16** (Simonyan and Zisserman 2014).

```{r fig.align='center'}
magick::image_read_pdf("figures/cnn.pdf", pages = 1)
```


---

## üèãÔ∏è‚Äç‚ôÇÔ∏èModel Training {visibility="hidden"}

The computer vision model is trained on the **M3 high-performance computing platform** (www.massive.org.au), using **TensorFlow** (Abadi et al. 2016) and **Keras** (Chollet et al. 2015).

- The training, validation and test set contains 64000, 16000 and 8000 images respectively.

- The distribution of the target variable $D$ is controlled such that it roughly follows a uniform distribution.

- Multiple models with different image resolutions are trained, the optimized model has input size $32 \times 32$. 


---

## `r fontawesome::fa_i("r-project")` `autovi` Package

::: {style="font-size:80%"}

The `autovi` package provides automated visual inference with **computer vision models**. It is available on CRAN and Github.

#### Core Methods

- Null residuals simulation: `rotate_resid()`
- Visual signal strength: `vss()`
- Comprehensive checks: `check()` and `summary_plot()`

:::

---

## üí°Example: Boston Housing

::: {style="font-size:80%"}

```{r}
housing <- read_csv(here::here("paper_2/data/housing.csv"))
```


```{r}
#| echo: true
#| fig-height: 4
#| fig-width: 6
fitted_model <- lm(MEDV ~ RM + LSTAT + PTRATIO, data = housing)
ggplot() +
  geom_point(aes(fitted(fitted_model), 
                 resid(fitted_model))) +
  theme_void()
```

:::

```{r}
#| echo: false
#| message: false
#| fig-height: 4
#| fig-width: 6
library(autovi)
checker <- auto_vi(fitted_model = fitted_model, 
                   keras_model = get_keras_model("vss_phn_32"))
checker$check_result <- readRDS(here::here("paper_2/data/check_result_1.rds"))
```

---

## `r fontawesome::fa_i("r-project")` `rotate_resid()`

::: {style="font-size:80%"}

Null residuals are simulated from the fitted model assuming it is **correctly specified**.

::: {.columns}

::: {.column width="50%"}

```{.r}
checker <- auto_vi(fitted_model = fitted_model, 
                   keras_model = get_keras_model("vss_phn_32"))
checker$rotate_resid()
```

```{r}
#| echo: false
#| message: false
checker$rotate_resid()
```

:::

::: {.column width="50%"}

```{.r}
checker$rotate_resid() |>
  checker$plot_resid()
```


```{r}
#| echo: false
#| message: false
#| fig-height: 4
#| fig-width: 6
checker$rotate_resid() |>
  checker$plot_resid()
```

:::

:::

:::

---

## `r fontawesome::fa_i("r-project")` `vss()`


::: {style="font-size:80%"}

::: {.columns}

::: {.column width="50%"}

#### Visual signal strength of the actual residual plot

```{.r}
checker$vss()
```

```{r}
#| echo: false
#| message: true
checker$vss()
```

:::

::: {.column width="50%"}

#### Visual signal strength of a null plot

```{.r}
checker$rotate_resid() |>
  checker$vss()
```


```{r}
#| echo: false
#| message: true
checker$rotate_resid() |>
  checker$vss()
```


:::

:::

:::

---

## `r fontawesome::fa_i("r-project")` `check()`

```{.r}
checker$check()
checker
```

```{r}
#| echo: false
#| message: true
checker
```

---

## `r fontawesome::fa_i("r-project")` `summary_plot()`

```{r}
#| echo: true
checker$summary_plot()
```


---

## üí°Example: Left-triangle

::: {style="font-size:70%"}

Breusch‚ÄìPagan test $p$-value = 0.0457

```{r fig.height=4, fig.width=6}
set.seed(452)
ori_x <- rand_lognormal()
dat <- heter_model(b = 0, x = closed_form(~-ori_x))$gen(300)

mod <- lm(y ~ x, data = dat)
my_vi <- autovi::auto_vi(fitted_model = mod)
my_vi$plot_resid() -> p1
```

```{r dpi=300}
my_vi$check_result <- readRDS(here::here("paper_2/data/fig1_check.rds"))
my_vi$summary_plot() +
  theme(legend.position = "bottom", legend.box="vertical") +
  labs(linetype = "") -> p2

patchwork::wrap_plots(p1, p2, ncol = 2)
```

:::

---

## üí°Example: Dinosaur

::: {style="font-size:70%"}

::: {.columns}

::: {.column width="50%"}

Ramsey Regression Equation Specification Error test $p$-value = 0.742

Breusch‚ÄìPagan test $p$-value = 0.36

Shapiro-Wilk test $p$-value = 9.21e-05

```{r fig.height=4, fig.width=6, dpi=300}
dino <- datasauRus::datasaurus_dozen %>% filter(dataset == "dino")
mod <- lm(y ~ ., data = select(dino, -dataset))

my_vi <- autovi::auto_vi(fitted_model = mod)
my_vi$plot_resid()
```

:::

::: {.column width="50%"}

```{r fig.height=4.5, fig.width=4.5, dpi=300}
my_vi$check_result <- readRDS(here::here("paper_2/data/dino_check.rds"))
my_vi$summary_plot() +
  theme(legend.position = "bottom", legend.box="vertical") +
  labs(linetype = "")
```

:::

:::

:::

---

## üß™Compared to Visual Tests {visibility="hidden"}

```{r fig.align='center'}
magick::image_read_pdf("figures/human-mosaic-1.pdf", pages = 1)
```

---

## üß™Compared to RESET and BP Tests {visibility="hidden"}

```{r fig.align='center'}
magick::image_read_pdf("figures/conv-mosaic-1.pdf", pages = 1)
```

---

## üß™Power Comparison {visibility="hidden"}

```{r fig.align='center'}
magick::image_read_pdf("figures/fig-power-1.pdf", pages = 1)
```

---

## üåêShiny Application {.center}

Don't want to install `TensorFlow`? 

Try our shiny web application: <https://shorturl.at/DNWzt>

---

## üß©Extensions

To diagnose models other than the **Classical Normal Linear Regression Model** (CNLRM), one can:

1. Use raw residuals, but be aware that violations **may not be identifiable and the test could be two-sided**.
2. Use transformed residuals that are **roughly normally distributed**.
3. **Reuse the pre-trained convolutional blocks** and train a new computer vision model with an appropriate distance measure.

---

## üé¨Takeaway

You can use `autovi` to

- Evaluate lineups of residual plots of linear regression models

- **Captures the magnitude of model violations** through visual signal strength

- Automatically **detect model misspecification** using a visual test

---


## Thanks! Any questions? {.center}

<br>

### üîóRelevant links

::: {.nonincremental}

`r fontawesome::fa_i("github")` tengmcing

`r fontawesome::fa_i("envelope")` patrick.li@monash.edu

üì¶ [`autovi`](https://github.com/TengMCing/autovi){target="_blank"}

üìú [Slides](https://github.com/TengMCing/use_r/tree/master/paper_2){target="_blank"}


:::


